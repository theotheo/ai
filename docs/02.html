<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><title>Введение в ИИ</title><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui" name="viewport"><link href="reveal.js/css/reveal.css" rel="stylesheet"><link rel="stylesheet" href="reveal.js/css/theme/blood.css" id="theme"><!--This CSS is generated by the Asciidoctor-Reveal.js converter to further integrate AsciiDoc's existing semantic with Reveal.js--><style type="text/css">.reveal div.right {
  float: right;
}

/* callouts */
.conum[data-value] {display:inline-block;color:#fff!important;background-color:rgba(50,150,50,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}</style><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
tex2jax: {
  inlineMath: [["\\(", "\\)"]],
  displayMath: [["\\[", "\\]"]],
  ignoreClass: "nostem|nolatexmath"
},
asciimath2jax: {
  delimiters: [["\\$", "\\$"]],
  ignoreClass: "nostem|noasciimath"
},
TeX: { equationNumbers: { autoNumber: "none" } }
});</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.4.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script><link href="reveal.js/lib/css/zenburn.css" rel="stylesheet"><script>var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? "reveal.js/css/print/pdf.css" : "reveal.js/css/print/paper.css";
document.getElementsByTagName( 'head' )[0].appendChild( link );</script><!--[if lt IE 9]><script src="reveal.js/lib/js/html5shiv.js"></script><![endif]--><link rel="stylesheet" href="asciidoctor-revealjs.css"></head><body><div class="reveal"><div class="slides"><section class="title" data-state="title"><h1>Введение в ИИ</h1><div class="preamble"> <script type="module" src="https://unpkg.com/x-frame-bypass"></script></div></section>
<section id="_acm_computing_classification_system_2012"><h2>ACM Computing Classification System (2012)</h2><div class="imageblock stretch" style=""><img src="images/2019-09-27-13-39-45.png" alt="2019 09 27 13 39 45" height="100%"></div>
<div class="paragraph"><p><a href="https://dl.acm.org/ccs/ccs.cfm?id=10010178&amp;lid=0.10010147.10010178" class="bare">https://dl.acm.org/ccs/ccs.cfm?id=10010178&amp;lid=0.10010147.10010178</a></p></div></section>
<section id="_ams_mathematics_subject_classification_2000"><h2>AMS Mathematics Subject Classification (2000)</h2><div class="ulist"><ul><li><p>68-XX			Computer science For papers involving machine computations and programs in a specific mathematical area, see Section–04 in that area</p><div class="ulist"><ul><li><p>68Txx		Artificial intelligence</p><div class="ulist"><ul><li><p>68T01  	General</p></li><li><p>68T05  	Learning and adaptive systems [See also 68Q32, 91E40]</p></li><li><p>68T10  	Pattern recognition, speech recognition {For cluster analysis, see 62H30}</p></li><li><p>68T15  	Theorem proving (deduction, resolution, etc.) [See also 03B35]</p></li><li><p>68T20  	Problem solving (heuristics, search strategies, etc.)</p></li><li><p>68T27  	Logic in artificial intelligence</p></li><li><p>68T30  	Knowledge representation</p></li><li><p>68T35  	Languages and software systems (knowledge-based systems, expert systems, etc.)</p></li><li><p>68T37  	Reasoning under uncertainty</p></li><li><p>68T40  	Robotics [See also 93C85]</p></li><li><p>68T42  	Agent technology</p></li><li><p>68T45  	Machine vision and scene understanding</p></li><li><p>68T50  	Natural language processing [See also 03B65]</p></li><li><p>68T99  	None of the above, but in this section</p></li></ul></div></li></ul></div></li></ul></div>
<div class="paragraph"><p><a href="https://mathscinet.ams.org/mathscinet/msc/msc2010.html?t=68Txx&amp;btn=Current" class="bare">https://mathscinet.ams.org/mathscinet/msc/msc2010.html?t=68Txx&amp;btn=Current</a></p></div></section>
<section><div class="olist arabic stretch"><ol class="arabic"><li><p>Knowledge representation and reasoning,</p></li><li><p>Natural language processing,</p></li><li><p>Machine Learning,</p></li><li><p>Planning,</p></li><li><p>Multi-agent systems,</p></li><li><p>Computer vision,</p></li><li><p>Robotics,</p></li><li><p>Philosophical aspects.</p></li></ol></div>
<div class="imageblock stretch" style=""><img src="images/2019-09-27-17-13-28.png" alt="2019 09 27 17 13 28" height="100%"></div></section>
<section id="_оптимизация"><h2>Оптимизация</h2><div class="paragraph"><p>Где-то что-то максимизируем/минимизируем</p></div>
<div class="olist arabic"><ol class="arabic"><li><p>Поиск: минимизируем путь в графе состояний</p></li><li><p>Поиск маршрута: минимизируем длину маршрута</p></li><li><p>Машинное обучение: минимизируем ошибку</p></li><li><p>Диалоговые системы: максимизируем вовлеченность</p></li></ol></div></section>
<section id="_искусственный_интеллект_по_nr"><h2>Искусственный интеллект по N&amp;R</h2><div class="imageblock stretch" style=""><img src="images/2019-09-27-15-21-38.png" alt="2019 09 27 15 21 38" height="100%"></div></section>
<section id="_агент"><h2>Агент</h2><div class="ulist"><ul><li><p>(рациональный) агент</p></li><li><p>восприятие (датчики)</p></li><li><p>окружение (среда)</p></li><li><p>пространство действий</p></li><li><p>техники для выбора действия</p></li></ul></div>
<div class="imageblock" style=""><img src="images/2019-09-27-15-23-44.png" alt="2019 09 27 15 23 44"></div></section>
<section><div class="imageblock stretch" style=""><img src="images/2019-09-27-17-20-04.png" alt="2019 09 27 17 20 04" height="100%"></div></section>
<section id="_условные_разделения"><h2>Условные разделения</h2><div class="ulist"><ul><li><p>Интеллект из вычислений</p><div class="ulist"><ul><li><p>Поиск (в пространстве состояний) / планирование</p></li><li><p>Constraint satisfaction</p></li><li><p>Adversarial</p></li></ul></div></li><li><p>Интеллект из данных</p><div class="ulist"><ul><li><p>Байесовские сети (вероятностные графические модели)</p></li><li><p>Машинное обучение</p><div class="ulist"><ul><li><p>Глубокое обучение</p></li></ul></div></li></ul></div></li><li><p>Приложения</p><div class="ulist"><ul><li><p>Игры (шахматы, ?)</p></li><li><p>Естественный язык (QA, машинный перевод)</p></li><li><p>Компьютерное зрение (детекция, сегментация)</p></li><li><p>Робототехника (??)</p></li></ul></div></li></ul></div></section>
<section id="_примеры"><h2>Примеры</h2><div class="paragraph"><p>Разделение по областям приблизительное</p></div></section>
<section><section id="_игры"><h2>Игры</h2></section><section id="_шахматы"><h2>Шахматы</h2><div class="imageblock stretch" style=""><img src="https://hackernoon.com/hn-images/0*uaznJmpQjAAWCXTY.png" alt="0*uaznJmpQjAAWCXTY" height="100%"></div>
<div class="paragraph"><p><a href="https://hackernoon.com/machines-that-play-deep-blue-5a2af4e739f7" class="bare">https://hackernoon.com/machines-that-play-deep-blue-5a2af4e739f7</a></p></div></section><section id="_jeopardy"><h2>Jeopardy!</h2><div class="imageblock stretch" style=""><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/DeepQA.svg/1600px-DeepQA.svg.png" alt="1600px DeepQA.svg" height="100%"></div></section><section id="_atari"><h2>Atari</h2><div class="imageblock stretch" style=""><img src="https://miro.medium.com/max/1600/1*3ZgGbUpEyAZb9POWijRq4Q.png" alt="1*3ZgGbUpEyAZb9POWijRq4Q" height="100%"></div></section><section id="_го"><h2>Го</h2></section><section id="_покер"><h2>Покер</h2></section><section id="_starcraft"><h2>StarCraft</h2><div class="imageblock stretch" style=""><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/T/TadaoYamaoka/20190804/20190804150322.png" alt="20190804150322" height="100%"></div></section><section id="_doom"><h2>Doom</h2><div class="imageblock stretch" style=""><img src="https://adriancolyer.files.wordpress.com/2016/11/fps-fig-2.png" alt="fps fig 2" height="100%"></div>
<div class="imageblock" style=""><img src="https://www.researchgate.net/profile/Ondrej_Miksik/publication/311299501/figure/fig1/AS:434684250333189@1480648210059/System-overview-a-Observing-image-and-depth-from-VizDoom-Running-Faster-RCNN-b-for.png" alt="System overview a Observing image and depth from VizDoom Running Faster RCNN b for"></div></section><section><div class="imageblock stretch" style=""><img src="images/2019-09-27-14-00-23.png" alt="2019 09 27 14 00 23" height="100%"></div></section></section>
<section><section id="_perception"><h2>Perception</h2></section><section id="_распознавать_речь_asr"><h2>Распознавать речь (ASR)</h2><div class="imageblock stretch" style=""><img src="https://www.degruyter.com/view/j/jisys.ahead-of-print/jisys-2018-0372/graphic/j_jisys-2018-0372_fig_001.jpg" alt="j jisys 2018 0372 fig 001" height="100%"></div></section><section><div class="imageblock stretch" style=""><img src="https://www.researchgate.net/publication/329716031/figure/fig3/AS:731591659753537@1551436452863/The-U-Net-architecture-in-the-example-of-a-2D-cell-segmentation-network-left-Input-An.jpg" alt="The U Net architecture in the example of a 2D cell segmentation network left Input An" height="100%"></div></section><section><div class="imageblock stretch" style=""><img src="https://miro.medium.com/max/1901/1*d4Eg17IVJ0L41e7CTWLLSg.png" alt="1*d4Eg17IVJ0L41e7CTWLLSg" height="100%"></div>
<div class="paragraph"><p><a href="https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b" class="bare">https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b</a></p></div></section></section>
<section><section id="_порождение"><h2>Порождение</h2></section><section id="_image_captioning"><h2>Image captioning</h2><div class="imageblock stretch" style=""><img src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/Example-of-the-CNN-and-LSTM-Architecture.png" alt="Example of the CNN and LSTM Architecture" height="100%"></div>
<div class="paragraph"><p><a href="https://machinelearningmastery.com/how-to-caption-photos-with-deep-learning/" class="bare">https://machinelearningmastery.com/how-to-caption-photos-with-deep-learning/</a></p></div></section><section id="_deep_voice"><h2>Deep Voice</h2><div class="imageblock stretch" style=""><img src="https://miro.medium.com/max/942/1*06JbKxq2eS9G8yO-fhELWg.png" alt="1*06JbKxq2eS9G8yO fhELWg" height="100%"></div></section><section id="_gpt_2"><h2>GPT-2</h2><div class="imageblock stretch" style=""><img src="http://jalammar.github.io/images/gpt2/gpt2-weights-2.png" alt="gpt2 weights 2" height="100%"></div>
<div class="paragraph"><p><a href="https://talktotransformer.com" class="bare">https://talktotransformer.com</a></p></div></section><section><div class="imageblock stretch" style=""><img src="http://tsong.me/public/img/reading/google-nmt-lstm.png" alt="google nmt lstm" height="100%"></div></section><section id="_recsys"><h2>RecSys</h2><div class="imageblock stretch" style=""><img src="https://miro.medium.com/max/7936/1*iG7vIW2hp870OQ_W_rEZzg.jpeg" alt="1*iG7vIW2hp870OQ W rEZzg" height="100%"></div></section></section>
<section><section id="_robotics"><h2>Robotics</h2></section><section id="_boston_dynamics"><h2>Boston Dynamics</h2></section><section id="_self_driving"><h2>Self-driving</h2><div class="imageblock stretch" style=""><img src="https://www.researchgate.net/profile/Luan_Ferreira_Reis_De_Jesus/publication/330383071/figure/fig1/AS:715180870750211@1547523815739/Overview-of-the-typical-hierarchical-architecture-of-self-driving-cars-TSD-denotes.png" alt="Overview of the typical hierarchical architecture of self driving cars TSD denotes" height="100%"></div></section></section>
<section><section id="_search"><h2>Search</h2></section><section id="_dfs"><h2>DFS</h2><div class="imageblock stretch" style=""><img src="images/2019-09-27-17-33-08.png" alt="2019 09 27 17 33 08" height="100%"></div>
<div class="paragraph"><p><a href="https://www.youtube.com/watch?v=qt6oMBKRxEU" class="bare">https://www.youtube.com/watch?v=qt6oMBKRxEU</a></p></div></section><section id="_bfs"><h2>BFS</h2><div class="imageblock stretch" style=""><img src="images/2019-09-27-17-33-08.png" alt="2019 09 27 17 33 08" height="100%"></div>
<div class="paragraph"><p><a href="https://www.youtube.com/watch?v=ec0IJsiIuWk&amp;t" class="bare">https://www.youtube.com/watch?v=ec0IJsiIuWk&amp;t</a></p></div></section><section id="_uniform_cost_search"><h2>Uniform Cost Search</h2><div class="imageblock stretch" style=""><img src="images/2019-09-27-17-34-18.png" alt="2019 09 27 17 34 18" height="100%"></div>
<div class="paragraph"><p><a href="https://www.youtube.com/watch?v=Z7_A3Ih-VjY" class="bare">https://www.youtube.com/watch?v=Z7_A3Ih-VjY</a></p></div></section></section></div></div><script src="reveal.js/lib/js/head.min.js"></script><script src="reveal.js/js/reveal.js"></script><script>Array.prototype.slice.call(document.querySelectorAll('.slides section')).forEach(function(slide) {
  if (slide.getAttribute('data-background-color')) return;
  // user needs to explicitly say he wants CSS color to override otherwise we might break custom css or theme (#226)
  if (!(slide.classList.contains('canvas') || slide.classList.contains('background'))) return;
  var bgColor = getComputedStyle(slide).backgroundColor;
  if (bgColor !== 'rgba(0, 0, 0, 0)' && bgColor !== 'transparent') {
    slide.setAttribute('data-background-color', bgColor);
    slide.style.backgroundColor = 'transparent';
  }
})

// See https://github.com/hakimel/reveal.js#configuration for a full list of configuration options
Reveal.initialize({
  // Display presentation control arrows
  controls: true,
  // Help the user learn the controls by providing hints, for example by
  // bouncing the down arrow when they first encounter a vertical slide
  controlsTutorial: true,
  // Determines where controls appear, "edges" or "bottom-right"
  controlsLayout: 'bottom-right',
  // Visibility rule for backwards navigation arrows; "faded", "hidden"
  // or "visible"
  controlsBackArrows: 'faded',
  // Display a presentation progress bar
  progress: true,
  // Display the page number of the current slide
  slideNumber: 'true',
  // Control which views the slide number displays on
  showSlideNumber: 'all',
  // Push each slide change to the browser history
  history: true,
  // Enable keyboard shortcuts for navigation
  keyboard: true,
  // Enable the slide overview mode
  overview: true,
  // Vertical centering of slides
  center: true,
  // Enables touch navigation on devices with touch input
  touch: true,
  // Loop the presentation
  loop: false,
  // Change the presentation direction to be RTL
  rtl: false,
  // Randomizes the order of slides each time the presentation loads
  shuffle: false,
  // Turns fragments on and off globally
  fragments: true,
  // Flags whether to include the current fragment in the URL,
  // so that reloading brings you to the same fragment position
  fragmentInURL: false,
  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,
  // Flags if we should show a help overlay when the questionmark
  // key is pressed
  help: true,
  // Flags if speaker notes should be visible to all viewers
  showNotes: false,
  // Global override for autolaying embedded media (video/audio/iframe)
  // - null: Media will only autoplay if data-autoplay is present
  // - true: All media will autoplay, regardless of individual setting
  // - false: No media will autoplay, regardless of individual setting
  autoPlayMedia: null,
  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,
  // Stop auto-sliding after user input
  autoSlideStoppable: true,
  // Use this method for navigation when auto-sliding
  autoSlideMethod: Reveal.navigateNext,
  // Specify the average time in seconds that you think you will spend
  // presenting each slide. This is used to show a pacing timer in the
  // speaker view
  defaultTiming: 120,
  // Enable slide navigation via mouse wheel
  mouseWheel: false,
  // Hides the address bar on mobile devices
  hideAddressBar: true,
  // Opens links in an iframe preview overlay
  // Add `data-preview-link` and `data-preview-link="false"` to customise each link
  // individually
  previewLinks: false,
  // Transition style (e.g., none, fade, slide, convex, concave, zoom)
  transition: 'slide',
  // Transition speed (e.g., default, fast, slow)
  transitionSpeed: 'default',
  // Transition style for full page slide backgrounds (e.g., none, fade, slide, convex, concave, zoom)
  backgroundTransition: 'fade',
  // Number of slides away from the current that are visible
  viewDistance: 3,
  // Parallax background image (e.g., "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'")
  parallaxBackgroundImage: '',
  // Parallax background size in CSS syntax (e.g., "2100px 900px")
  parallaxBackgroundSize: '',
  // Number of pixels to move the parallax background per slide
  // - Calculated automatically unless specified
  // - Set to 0 to disable movement along an axis
  parallaxBackgroundHorizontal: null,
  parallaxBackgroundVertical: null,
  // The display mode that will be used to show slides
  display: 'block',

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: '200%',
  height: 1200,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 1.5,

  // Optional libraries used to extend on reveal.js
  dependencies: [
      { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
      
      { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
      { src: 'reveal.js/plugin/notes/notes.js', async: true },
      
      
      
      { src: 'revealjs-plugins/reveal.js-menu/menu.js' },
{ src: 'revealjs-plugins/chalkboard/chalkboard.js' },
{ src: 'revealjs-plugins/reveal-code-focus/reveal-code-focus.js' }

  ],

  menu: {
	side: 'right',
	openSlideNumber: true,
	numbers: true,
},
keyboard: {
	    67: function() { RevealChalkboard.toggleNotesCanvas() },	// toggle notes canvas when 'c' is pressed
	    66: function() { RevealChalkboard.toggleChalkboard() },	// toggle chalkboard when 'b' is pressed
	    46: function() { RevealChalkboard.clear() },	// clear chalkboard when 'DEL' is pressed
	     8: function() { RevealChalkboard.reset() },	// reset chalkboard data on current slide when 'BACKSPACE' is pressed
		68: function() { RevealChalkboard.download() },	// downlad recorded chalkboard drawing when 'd' is pressed,
		70: function() { RevealChalkboard.colorNext() },	// cycle colors forward when 'f' is pressed
	    71: function() { RevealChalkboard.colorPrev() },	// cycle colors backward when 'g' is pressed

},
chalkboard: { 
	toggleChalkboardButton: { left: "60px", bottom: "30px", top: "auto", right: "auto" },
	toggleNotesButton: { left: "90px", bottom: "30px", top: "auto", right: "auto" },
	readOnly: false,
	theme: 'whiteboard'
}


});</script></body></html>